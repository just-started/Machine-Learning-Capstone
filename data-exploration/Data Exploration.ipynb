{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration for a Machine Learning Stock Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named matplotlib.pyplot",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-05a75c1d169d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'matplotlib inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named matplotlib.pyplot"
     ]
    }
   ],
   "source": [
    "# import needed libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions\n",
    "---\n",
    "\n",
    "Global functions intended to make computations easier. These are also developed with the intention to be used in the final code implimentaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "################################################\n",
    "# Data Gathering Helpers\n",
    "################################################\n",
    "def path_to_data(ticker, base_dir='data'):\n",
    "    return os.path.join(base_dir, '{}.csv'.format(ticker))\n",
    "\n",
    "def fetch_data(ticker_list, dates):\n",
    "    df = pd.DataFrame(index=dates)\n",
    "    \n",
    "    if 'SPY' not in ticker_list:\n",
    "        ticker_list.insert(0, 'SPY')\n",
    "        \n",
    "    for ticker in range(0, len(ticker_list)):\n",
    "        df_temp = pd.read_csv(\n",
    "            path_to_data(ticker_list[ticker]), \n",
    "            usecols=['Date', 'Adj Close'], \n",
    "            index_col='Date', \n",
    "            parse_dates=True, \n",
    "            na_values=['nan'])\n",
    "        df_temp = df_temp.rename(columns={'Adj Close' : ticker_list[ticker]})\n",
    "        df = df.join(df_temp)\n",
    "    \n",
    "    df = df.dropna(subset=['SPY'])\n",
    "    df.fillna(method='ffill', inplace=True)\n",
    "    df.fillna(method='bfill', inplace=True)\n",
    "    return df\n",
    "\n",
    "################################################\n",
    "# STATS Helpers\n",
    "################################################\n",
    "def normalize_data(df):\n",
    "    return df/df.iloc[0,:]\n",
    "\n",
    "def print_stats(df):\n",
    "    print 'Global Mean:'\n",
    "    print df.mean()\n",
    "    print '\\nGlobal Median:'\n",
    "    print df.median()\n",
    "    print '\\nGlobal Std:'\n",
    "    print df.std()\n",
    "\n",
    "def get_daily_returns(df):\n",
    "    daily_returns = df.copy()\n",
    "    daily_returns[1:] = (daily_returns[1:] / daily_returns[0:-1].values) - 1\n",
    "    daily_returns.iloc[0, : ] = 0\n",
    "    return daily_returns\n",
    "\n",
    "# rolling stats\n",
    "def get_rolling_mean(vals, window=20):\n",
    "    return vals.rolling(window,center=False).mean()\n",
    "\n",
    "def get_rolling_std(vals, window=20):\n",
    "    return vals.rolling(window,center=False).std()\n",
    "\n",
    "def get_bollinger_bands(rolling_mean, rolling_std):\n",
    "    lower_band = rolling_mean - (rolling_std * 2)\n",
    "    upper_band = rolling_mean + (rolling_std * 2)\n",
    "    return lower_band, upper_band\n",
    "\n",
    "def get_bollinger_ratios(series, sma, r_std, window=20):\n",
    "    bb = series.copy()\n",
    "    bb[window:] = (bb[window:] - sma[window:]) / (2 * r_std[window:])\n",
    "    return bb[window:]\n",
    "\n",
    "def get_momentum(df, window=20):\n",
    "    momentum = df.copy()\n",
    "    momentum[window:] = (momentum[window:] / momentum[0:-window].values) - 1\n",
    "    return momentum[window:]\n",
    "\n",
    "def get_sma_ratio(df, window=20):\n",
    "    sma = df.copy()\n",
    "    sma[window:] = (sma[window:] / sma[0:-window].mean()) - 1\n",
    "    return sma[window:]\n",
    "\n",
    "def normalize_feature(series):\n",
    "    return (series - series.mean())/series.std()\n",
    "\n",
    "################################################\n",
    "# Graph Plotting Helpers\n",
    "################################################\n",
    "def plot_hist_with_stats(df, bins=10, title=''):\n",
    "    \n",
    "    mean = df.mean()\n",
    "    std = df.std()\n",
    "    \n",
    "    df.hist(bins=bins)\n",
    "    plt.axvline(mean, color='w', linestyle='dashed', linewidth=2)\n",
    "    plt.axvline(mean + std, color='r', linestyle='dashed', linewidth=2)\n",
    "    plt.axvline(mean - std, color='r', linestyle='dashed', linewidth=2)\n",
    "    plt.show()\n",
    "\n",
    "def plot_hist_multi(df, bins=10, title=''):\n",
    "    for stock in df:\n",
    "        df[stock].hist(bins=bins, label=stock, alpha = 0.5)\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "    \n",
    "def print_bollinger_bands(series, rolling_mean, lower_band, upper_band, label=''):\n",
    "    val = ax = series.plot(title='Bollinger Bands: ' + label, label='Prices', fontsize=10)\n",
    "    rm = rolling_mean.plot(label='Rolling Mean', ax=ax)\n",
    "    ub = upper_band.plot(label='Upper Band', ax=ax)\n",
    "    lb = lower_band.plot(label='Lower Band', ax=ax)\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    ax.legend(handles, labels, loc='best')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_momentum(series, rolling_mean, label=''):\n",
    "    val = ax = series.plot(title='Momentum: ' + label, label='Prices', fontsize=10)\n",
    "    rm = rolling_mean.plot(label='Rolling Mean', ax=ax)\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    ax.legend(handles, labels, loc='best')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_data(df, title='Stock Prices', xlabel='Date', ylabel='Price'):\n",
    "    ax = df.plot(title=title, fontsize=10)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    plt.show()\n",
    "    \n",
    "def plot_predictions(true_vals, pred_vals, x_label='Actual', y_label='CLF Predictions'):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(actual_vals, pred_vals)\n",
    "    ax.plot([pred_vals.min(), pred_vals.max()], [pred_vals.min(), pred_vals.max()], 'k--', lw=4)\n",
    "    ax.set_xlabel(x_label)\n",
    "    ax.set_ylabel(y_label)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Data for Selected Stocks\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use two years of dates for data exploration\n",
    "dates = pd.date_range('2015-07-14', '2017-07-14')\n",
    "\n",
    "ticker = 'NVDA'\n",
    "metrics_window = 10\n",
    "\n",
    "# These will be the tickers we will be working with to build our model\n",
    "# SPY is added as a benchmark model. \n",
    "tickers = [ticker]\n",
    "\n",
    "\n",
    "df_explore = fetch_data(tickers, dates)\n",
    "print df_explore.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Data of the Selected Stocks\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(df_explore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_data = normalize_data(df_explore)\n",
    "plot_data(normalized_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Stats\n",
    "---\n",
    "\n",
    "Global stats of the stocks we are interested in\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_stats(df_explore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rolling Stats\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_mean = get_rolling_mean(df_explore[ticker], metrics_window)\n",
    "rolling_std = get_rolling_std(df_explore[ticker], metrics_window)\n",
    "lower_band, upper_band = get_bollinger_bands(rolling_mean, rolling_std)\n",
    "\n",
    "print_bollinger_bands(df_explore[ticker], rolling_mean, lower_band, upper_band, ticker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daily Returns\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_returns  = get_daily_returns(df_explore)\n",
    "plot_data(daily_returns[ticker], title='Daily Returns for ' + ticker, xlabel='Date', ylabel='Daily Return')\n",
    "\n",
    "print 'Max/Min Daily Returns for ' + ticker\n",
    "print 'Max:', daily_returns[ticker].max()\n",
    "print 'Min:', daily_returns[ticker].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist_with_stats(daily_returns[ticker], bins=15, title=ticker)\n",
    "plot_hist_multi(daily_returns, bins=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Momentum\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "momentum = get_momentum(df_explore[ticker], window=metrics_window)\n",
    "\n",
    "plot_data(momentum, title='Momentum of ' + ticker, xlabel='Date', ylabel='Momentum')\n",
    "plot_hist_with_stats(momentum, bins=40, title=ticker)\n",
    "\n",
    "print 'Max/Min Momentum for ' + ticker\n",
    "print 'Max:', momentum.max()\n",
    "print 'Min:', momentum.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Moving Average Ratio\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sma_ratios = get_sma_ratio(df_explore[ticker], window=metrics_window)\n",
    "\n",
    "plot_data(sma_ratios, title='SMA Ratios of NVDA', xlabel='Date', ylabel='SMA Ratio[Day]')\n",
    "plot_hist_with_stats(sma_ratios, bins=40, title=ticker)\n",
    "\n",
    "print 'Max/Min SMA Ratio for ' + ticker\n",
    "print 'Max: ', sma_ratios.max()\n",
    "print 'Min: ', sma_ratios.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bolinger Ratios\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb_ratios = get_bollinger_ratios(series=df_explore[ticker], sma=rolling_mean, r_std=rolling_std, window=metrics_window)\n",
    "\n",
    "plot_data(bb_ratios, title='Bollinger Ratios of ' + ticker, xlabel='Date', ylabel='Bollinger Ratio[Day]')\n",
    "plot_hist_with_stats(bb_ratios, bins=20, title=ticker)\n",
    "\n",
    "print 'Max/Min BB Ratio for ' + ticker\n",
    "print 'Max:', bb_ratios.max()\n",
    "print 'Min:', bb_ratios.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up the Feature Set\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recombine the features into a new Data Frame X and Y. \n",
    "# X will be a frame of all the featres for and Y will be the outcomes\n",
    "\n",
    "d = { 'BB_RATIOS' : bb_ratios, 'SMA_RATIOS' : sma_ratios, 'MOMENTUM' : momentum }\n",
    "features_df = pd.DataFrame(d)\n",
    "\n",
    "X_features = features_df[0 : -1].values\n",
    "y_target = df_explore[ticker][(metrics_window + 1) : ].values\n",
    "\n",
    "X_faetures_7152017 = features_df.tail(1)\n",
    "\n",
    "print 'Features Length', len(X_features)\n",
    "print 'Target Length', len(y_target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_knn = Pipeline([\n",
    "        ('scl', StandardScaler()),\n",
    "        ('clf', KNeighborsRegressor(n_neighbors=5, weights='distance'))\n",
    "    ])\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=3)\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "final_predics = []\n",
    "actual_vals = []\n",
    "\n",
    "for train_index, test_index in tscv.split(X_features):\n",
    "    pipe_knn.fit(X_features[train_index], y_target[train_index])\n",
    "    \n",
    "    train_score = pipe_knn.score(X_features[train_index], y_target[train_index])\n",
    "    test_score = pipe_knn.score(X_features[test_index], y_target[test_index])\n",
    "    \n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "    \n",
    "    final_predic = pipe_knn.predict(X_features[test_index])\n",
    "    actual_vals = y_target[test_index]\n",
    "\n",
    "print '\\nTrain scores', train_scores\n",
    "print 'Train Scores Mean {}, Train Scores STD {}'.format(np.asarray(train_scores).mean(), np.asarray(train_scores).std())\n",
    "\n",
    "print '\\nTest scores', test_scores\n",
    "print 'Test Scores Mean {}, Test Scores STD {}'.format(np.asarray(test_scores).mean(), np.asarray(test_scores).std())\n",
    "\n",
    "print '\\nPredictions', final_predic[0: 12]\n",
    "\n",
    "print '\\nActual', actual_vals[0: 12]\n",
    "\n",
    "plot_predictions(actual_vals, final_predic, y_label='KNN Predictions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pipe_lr = Pipeline([\n",
    "        ('scl', StandardScaler()),\n",
    "        ('clf', LinearRegression())\n",
    "    ])\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=3)\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "final_predics = []\n",
    "actual_vals = []\n",
    "\n",
    "for train_index, test_index in tscv.split(X_features):\n",
    "    pipe_lr.fit(X_features[train_index], y_target[train_index])\n",
    "    \n",
    "    train_score = pipe_lr.score(X_features[train_index], y_target[train_index])\n",
    "    test_score = pipe_lr.score(X_features[test_index], y_target[test_index])\n",
    "    \n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "    \n",
    "    final_predic = pipe_lr.predict(X_features[test_index])\n",
    "    actual_vals = y_target[test_index]\n",
    "\n",
    "print '\\nTrain scores', train_scores\n",
    "print 'Train Scores Mean {}, Train Scores STD {}'.format(np.asarray(train_scores).mean(), np.asarray(train_scores).std())\n",
    "\n",
    "print '\\nTest scores', test_scores\n",
    "print 'Test Scores Mean {}, Test Scores STD {}'.format(np.asarray(test_scores).mean(), np.asarray(test_scores).std())\n",
    "\n",
    "print '\\nPredictions', final_predic[0: 12]\n",
    "\n",
    "print '\\nActual', actual_vals[0: 12]\n",
    "\n",
    "X_faetures_7152017 = pipe_lr.predict(features_df.tail(1))\n",
    "print '\\nAdjusted value first day after Selected Dates\\n', X_faetures_7152017\n",
    "\n",
    "plot_predictions(actual_vals, final_predic, y_label='Linear Regression Predictions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf = RandomForestRegressor(n_estimators=5)\n",
    "tscv = TimeSeriesSplit(n_splits=3)\n",
    "\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "final_predics = []\n",
    "actual_vals = []\n",
    "\n",
    "for train_index, test_index in tscv.split(X_features):\n",
    "    clf_rf.fit(X_features[train_index], y_target[train_index])\n",
    "    \n",
    "    train_score = clf_rf.score(X_features[train_index], y_target[train_index])\n",
    "    test_score = clf_rf.score(X_features[test_index], y_target[test_index])\n",
    "    \n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "    \n",
    "    final_predic = clf_rf.predict(X_features[test_index])\n",
    "    actual_vals = y_target[test_index]\n",
    "\n",
    "print '\\nTrain scores', train_scores\n",
    "print 'Train Scores Mean {}, Train Scores STD {}'.format(np.asarray(train_scores).mean(), np.asarray(train_scores).std())\n",
    "\n",
    "print '\\nTest scores', test_scores\n",
    "print 'Test Scores Mean {}, Test Scores STD {}'.format(np.asarray(test_scores).mean(), np.asarray(test_scores).std())\n",
    "\n",
    "print '\\nPredictions', final_predic[0: 12]\n",
    "\n",
    "print '\\nActual', actual_vals[0: 12]\n",
    "\n",
    "plot_predictions(actual_vals, final_predic, y_label='Random Forest Predictions')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "---\n",
    "After running my predictions through 3 different classifers the only one worth looking forward on is the Linear Regresion classifier.\n",
    "\n",
    "The scores are more than acceptable, and based on the score on the training and testing set it does not seem to be overfitting.\n",
    "\n",
    "Running through a few different stocks indicates that the more volitile the stock the worse the predictions are.\n",
    "\n",
    "My goal now is to write some classes and functions that will be usefull in the final presentation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin Evaluation from API\n",
    "---\n",
    "\n",
    "In the following section we will be rewriting the helper functions into classes to use in the final UI as well as connecting to Yahoo api as that will be what is used in the final UI. It will also give us the opportunity to compare how well the classifier works against our static files with the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas_datareader import data, wb\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "class Stock_Time_Series:\n",
    "    def __init__(self, to_date=datetime.datetime.now(), year_span=2):\n",
    "        start_date = to_date - relativedelta(years=year_span)\n",
    "        self.dates = pd.date_range(start_date, to_date)\n",
    "                \n",
    "    def fetch_data(self, symbol_list):\n",
    "        self.df = pd.DataFrame(index=self.dates)\n",
    "        good_symbols = []\n",
    "        bad_symbols = []\n",
    "        \n",
    "        if 'SPY' not in symbol_list:\n",
    "            symbol_list.insert(0, 'SPY')\n",
    "\n",
    "        for symbol in symbol_list:\n",
    "            try:\n",
    "                fetched_data = data.DataReader(symbol, 'yahoo', self.dates[0], self.dates[-1])\n",
    "                fetched_data = fetched_data.rename(columns={'Adj Close' : symbol})\n",
    "                self.df[symbol] = fetched_data[symbol]\n",
    "                good_symbols.append(symbol)\n",
    "            except Exception:\n",
    "                bad_symbols.append(symbol)\n",
    "\n",
    "        self.df = self.df.dropna(subset=['SPY'])\n",
    "        self.df.fillna(method='ffill', inplace=True)\n",
    "        self.df.fillna(method='bfill', inplace=True)\n",
    "        return self.df, good_symbols, bad_symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this will be our classifer interface\n",
    "class Stock_Classifier:\n",
    "    def __init__(self, n_splits=3):\n",
    "        self.n_splits = n_splits\n",
    "        self.clf = Pipeline([\n",
    "            ('scl', StandardScaler()),\n",
    "            ('clf', LinearRegression())\n",
    "        ])\n",
    "        self.cv = TimeSeriesSplit(n_splits=self.n_splits)\n",
    "    \n",
    "    def get_cv_splits(self, X, y):\n",
    "        train_splits = []\n",
    "        test_splits = []\n",
    "        \n",
    "        for train_index, test_index in self.cv.split(X):\n",
    "            train_splits.append(train_index)\n",
    "            test_splits.append(test_index)\n",
    "            \n",
    "        return train_splits, test_splits\n",
    "            \n",
    "    def train(self, X, y, split_indexes):      \n",
    "        for set_index in split_indexes:\n",
    "            self.clf.fit(X[set_index], y[set_index])\n",
    "    \n",
    "    def score(self, X, y, split_indexes):\n",
    "        scores = []\n",
    "        for set_index in split_indexes:\n",
    "            scores.append(self.clf.score(X[set_index], y[set_index]))\n",
    "        return scores\n",
    "    \n",
    "    def full_set_train(self, X, y):\n",
    "        self.clf.fit(X, y)\n",
    "        \n",
    "    def query(self, X):\n",
    "        return self.clf.predict(X)\n",
    "    \n",
    "    def get_splits(self):\n",
    "        return self.n_splits\n",
    "\n",
    "\n",
    "    \n",
    "class Stock_Explorer:\n",
    "    def __init__(self, series, symbol, rolling_window_size=10, prediction_window_size=14):\n",
    "        self.symbol = symbol\n",
    "        self.stock_clf = Stock_Classifier()\n",
    "        self.series = series\n",
    "        self.rolling_window_size = rolling_window_size\n",
    "        self.prediction_window_size = prediction_window_size\n",
    "    \n",
    "    def get_json(self):\n",
    "        final_json = {}\n",
    "        \n",
    "        # if set is empty send back error error\n",
    "        if len(self.series) <= self.stock_clf.get_splits():\n",
    "            final_json['error'] = 'Error with Data'\n",
    "            return final_json\n",
    "        \n",
    "        # split and train\n",
    "        self.__get_X_y()\n",
    "        train_test_data = self.__train_and_test()\n",
    "        \n",
    "        # predict the new vals\n",
    "        self.__predict_vals()\n",
    "        \n",
    "        #bb bands\n",
    "        lower_bb, upper_bb = self.__get_bollinger_bands()\n",
    "        \n",
    "        final_json['Symbol'] = self.symbol\n",
    "        final_json['BB_Ratios'] = self.X_features['BB_RATIOS'].values.tolist()\n",
    "        final_json['Momentum'] = self.X_features['MOMENTUM'].values.tolist()\n",
    "        final_json['SMA_Ratios'] = self.X_features['SMA_RATIOS'].values.tolist()\n",
    "        final_json['SMA'] = self.__get_rolling_mean().values.tolist()\n",
    "        final_json['Lower_bb'] = lower_bb.values.tolist()\n",
    "        final_json['Upper_bb'] = upper_bb.values.tolist()\n",
    "        final_json['Target_Vals'] = self.y_target.values.tolist()\n",
    "        \n",
    "        final_json['Stats'] = self.__get_stats()\n",
    "        final_json['Prediction_Size'] = self.prediction_window_size\n",
    "        final_json['Train_Test_Data'] = train_test_data\n",
    "        final_json['Dates'] = self.__dates_to_string()\n",
    "        \n",
    "        return final_json\n",
    "    \n",
    "    def __dates_to_string(self):\n",
    "        dates = self.series.index.strftime('%Y-%m-%d').tolist()\n",
    "        return dates[self.rolling_window_size:]\n",
    "        \n",
    "    def __predict_vals(self):\n",
    "        pw = self.prediction_window_size\n",
    "        \n",
    "        for i in range(0 , pw):\n",
    "            pred_val = self.stock_clf.query(self.X_features.tail(1).values)[0]\n",
    "            self.__update_series(pred_val)\n",
    "    \n",
    "    def __update_series(self, new_val):\n",
    "        new_date = self.series.index[-1] + relativedelta(days=1)\n",
    "        new_target = pd.Series([new_val], index=[new_date])\n",
    "        self.series = self.series.append(new_target)\n",
    "        self.__get_X_y()\n",
    "        \n",
    "    def __get_X_y(self):\n",
    "        w = self.rolling_window_size\n",
    "        features_df = { 'BB_RATIOS' : self.__get_bollinger_ratios(), \n",
    "             'SMA_RATIOS' : self.__get_sma_ratio(), \n",
    "             'MOMENTUM' : self.__get_momentum()}\n",
    "        features_df = pd.DataFrame(features_df)\n",
    "        \n",
    "        self.X_features = features_df\n",
    "        self.y_target = self.series[w:]\n",
    "        \n",
    "    \n",
    "    def __train_and_test(self):\n",
    "        X = self.X_features[0 : -1].values\n",
    "        y = self.y_target[1 : ].values\n",
    "        \n",
    "        train_splits, test_splits = self.stock_clf.get_cv_splits(X, y)\n",
    "        self.stock_clf.train(X, y, train_splits)\n",
    "        train_scores = self.stock_clf.score(X, y, train_splits)\n",
    "        test_scores = self.stock_clf.score(X, y, test_splits)\n",
    "        \n",
    "        self.stock_clf.full_set_train(X, y)\n",
    "        \n",
    "        return {'train_mean' : np.asarray(train_scores).mean(), 'train_std' : np.asarray(train_scores).std(),\n",
    "              'test_mean' : np.asarray(test_scores).mean(), 'test_std' : np.asarray(test_scores).std()}\n",
    "    \n",
    "    def __get_rolling_mean(self):\n",
    "        w = self.rolling_window_size\n",
    "        sma = self.series.rolling(w, center=False).mean()\n",
    "        return sma[w:]\n",
    "\n",
    "    def __get_rolling_std(self):\n",
    "        w = self.rolling_window_size\n",
    "        r_std = self.series.rolling(w, center=False).std()\n",
    "        return r_std[w:]\n",
    "\n",
    "    def __get_bollinger_bands(self):\n",
    "        lower_band = self.__get_rolling_mean() - (self.__get_rolling_std() * 2)\n",
    "        upper_band = self.__get_rolling_mean() + (self.__get_rolling_std() * 2)\n",
    "        return lower_band, upper_band\n",
    "\n",
    "    def __get_bollinger_ratios(self):\n",
    "        bb = self.series.copy()\n",
    "        sma = self.__get_rolling_mean()\n",
    "        r_std = self.__get_rolling_std()\n",
    "        w = self.rolling_window_size\n",
    "        bb[w:] = (bb[w:] - sma) / (2 * r_std)\n",
    "        return bb[w:]\n",
    "\n",
    "    def __get_momentum(self):\n",
    "        momentum = self.series.copy()\n",
    "        w = self.rolling_window_size\n",
    "        momentum[w:] = (momentum[w:] / momentum[0:-w].values) - 1\n",
    "        return momentum[w:]\n",
    "\n",
    "    def __get_sma_ratio(self):\n",
    "        sma = self.series.copy()\n",
    "        w = self.rolling_window_size\n",
    "        sma[w:] = (sma[w:] / sma[0:-w].mean()) - 1\n",
    "        return sma[w:]\n",
    "\n",
    "    def __get_normalize_values(self):\n",
    "        return self.series/self.series[0:1].values\n",
    "    \n",
    "    def __get_stats(self):\n",
    "        vals = self.series.values\n",
    "        return {\n",
    "            'Mean' : np.mean(vals),\n",
    "            'Median' : np.median(vals),\n",
    "            'Std' : np.std(vals)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impliment the interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_date = datetime.datetime(2017, 7, 14)\n",
    "sts = Stock_Time_Series()\n",
    "\n",
    "stocks_df, good_symbols, bad_symbols = sts.fetch_data(['NVDA'])\n",
    "\n",
    "print 'Successful calls:', good_symbols\n",
    "print 'Bad calls:', bad_symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_n = Stock_Explorer(stocks_df['NVDA'], 'NVDA')\n",
    "\n",
    "f = test_n.get_json()\n",
    "\n",
    "\n",
    "for it in f:\n",
    "    print '\\n\\n', it\n",
    "    print f[it]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
